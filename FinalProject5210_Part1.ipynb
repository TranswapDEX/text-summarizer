{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blake Myers and Nicolas Stencel, Part 1 of the final project for CSCE 5210\n",
    "# Creating an extractive text summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import csv\n",
    "import os\n",
    "import networkx as nx\n",
    "import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP :\n",
    "  def __init__(self,lang='en'):\n",
    "    #stanza.download(lang)\n",
    "    self.nlp = stanza.Pipeline(lang=lang,logging_level='WARN')\n",
    "\n",
    "  def from_file(self,fname='texts/english'):\n",
    "    self.fname=fname\n",
    "    text = file2text(fname + \".txt\")\n",
    "    self.doc = self.nlp(text)\n",
    "\n",
    "  def from_text(self,text=\"Hello!\"):\n",
    "    self.doc = self.nlp(text)\n",
    "\n",
    "  def keynoun(self,x):\n",
    "    return  x.upos == 'NOUN' and ('subj' in x.deprel or 'ob' in x.deprel)\n",
    "\n",
    "  def facts(self):\n",
    "    def fact(x,sent,sid) :\n",
    "      if x.head==0 :\n",
    "        yield x.lemma,x.upos+'_PREDICATE_OF',sid,sid\n",
    "      else :\n",
    "        hw=sent.words[x.head-1]\n",
    "        if self.keynoun(x):\n",
    "          yield hw.lemma, hw.upos + \"rev_\"+x.deprel + x.upos, x.lemma, sid\n",
    "          yield (sid, 'ABOUT', x.lemma, sid)\n",
    "        else:\n",
    "          yield x.lemma,x.upos+x.deprel+hw.upos,hw.lemma,sid\n",
    "        if  x.deprel in (\"compound\",\"flat\") :\n",
    "          comp = x.lemma+\" \"+hw.lemma\n",
    "          yield x.lemma, x.upos+\"inCOMPOUND\", comp, sid\n",
    "          yield hw.lemma, hw.upos + \"inCOMPOUND\", comp, sid\n",
    "          yield (sid, 'ABOUT', comp, sid)\n",
    "\n",
    "    for sid,sent in enumerate(self.doc.sentences) :\n",
    "      for x in sent.words :\n",
    "        yield from fact(x,sent,sid)\n",
    "\n",
    "  def keynouns(self):\n",
    "    '''collects important nouns'''\n",
    "    ns=set()\n",
    "    for sent in self.doc.sentences:\n",
    "      for x in sent.words:\n",
    "        if self.keynoun(x) :\n",
    "          ns.add(x.lemma)\n",
    "    return ns\n",
    "\n",
    "  def info(self,wk=8,sk=6):\n",
    "    g=self.to_nx()\n",
    "    ranks=nx.pagerank(g)\n",
    "    ns=self.keynouns()\n",
    "    kwds,sids=ranks2info(ranks,ns,wk,sk)\n",
    "    sents=list(map(self.get_sent,sorted(sids)))\n",
    "    return kwds,sents\n",
    "\n",
    "  def to_nx(self):\n",
    "    return facts2nx(self.facts())\n",
    "\n",
    "  def to_tsv(self):\n",
    "    facts2tsv(self.facts(),\"out/\"+self.fname+\".tsv\")\n",
    "    self.to_sents()\n",
    "\n",
    "  def to_prolog(self):\n",
    "    facts2prolog(self.facts(),\"out/\"+self.fname+\".pro\")\n",
    "\n",
    "  def get_sent(self,sid) :\n",
    "    return self.doc.sentences[sid].text\n",
    "\n",
    "  def to_sents(self):\n",
    "    def sent_gen():\n",
    "       for sid,sent in enumerate(self.doc.sentences):\n",
    "         yield sid,sent.text\n",
    "    facts2tsv(sent_gen(),\"out/\"+self.fname+\"_sents.tsv\")\n",
    "\n",
    "  def summarize(self,wk=8,sk=5):\n",
    "    kws,sents=self.info(wk,sk)\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    for sent in sents : print(sent)\n",
    "    print(\"\\nKEYWORDS:\")\n",
    "    for w in kws : print(w,end='; ')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2text(fname) :\n",
    "  with open(fname,'r') as f:\n",
    "    return f.read()\n",
    "\n",
    "def facts2nx(fgen) :\n",
    "   g=nx.DiGraph()\n",
    "   for f,rel,t,id in fgen :\n",
    "     g.add_edge(f,t)\n",
    "   return g\n",
    "\n",
    "def ranks2info(ranks,keyns,wk,sk) :\n",
    "  ranked=sorted(ranks.items(),key=(lambda x: x[1]),reverse=True)\n",
    "  sids=[]\n",
    "  kwds=[]\n",
    "  for x, r in ranked:\n",
    "    if wk<=0 : break\n",
    "    if isinstance(x,str) and x in keyns:\n",
    "      kwds.append(x)\n",
    "      wk-=1\n",
    "  for x,r in ranked:\n",
    "    if sk <= 0: break\n",
    "    if isinstance(x, int):\n",
    "      sids.append(x)\n",
    "      sk -= 1\n",
    "  return kwds,sids\n",
    "\n",
    "def facts2tsv(fgen,fname) :\n",
    "  ensure_path(fname)\n",
    "  with open(fname, 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    for fact in fgen:\n",
    "      writer.writerow(fact)\n",
    "\n",
    "def facts2prolog(fgen,fname) :\n",
    "  ensure_path(fname)\n",
    "  with open(fname, 'w') as f:\n",
    "    for fact in fgen:\n",
    "      print('edge',end='',file=f)\n",
    "      print(fact,end=\".\\n\",file=f)\n",
    "\n",
    "def exists_file(fname):\n",
    "  return os.path.exists(fname)\n",
    "\n",
    "def home_dir() :\n",
    "  from pathlib import Path\n",
    "  return str(Path.home())\n",
    "\n",
    "def ensure_path(fname) :\n",
    "  dir,_=os.path.split(fname)\n",
    "  os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY:\n",
      "And the time?\n",
      "On the stroke of midnight, as a matter of fact.\n",
      "And, outside the window, fireworks and crowds.\n",
      "I, Saleem Sinai, later variously called Snotnose, Stainface, Baldy, Sniffer, Buddha and even Piece-of-the-Moon, had become heavily embroiled in Fate—at the best of times a dangerous sort of involvement.\n",
      "I must work fast, faster than Scheherazade, if I am to end up meaning — yes, meaning — something.\n",
      "\n",
      "KEYWORDS:\n",
      "night; time; meaning; instant; year; say; date; thanks; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(fname='texts/english',lang='en') :\n",
    "  nlp=NLP(lang)\n",
    "  nlp.from_file(fname)\n",
    "  nlp.to_tsv()\n",
    "  nlp.to_prolog()\n",
    "  nlp.summarize()\n",
    "\n",
    "if __name__==\"__main__\" :\n",
    "  test(fname='texts/english',lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text: I was born in the city of Bombay … once upon a time. No, that won’t do, there’s no getting away from the date: I was born in Doctor Narlikar’s Nursing Home on August 15th, 1947. And the time? The time matters, too. Well then: at night. No, it’s important to be more … On the stroke of midnight, as a matter of fact. Clock-hands joined palms in respectful greeting as I came. Oh, spell it out, spell it out: at the precise instant of India’s arrival at independence, I tumbled forth into the world. There were gasps. And, outside the window, fireworks and crowds. A few seconds later, my father broke his big toe; but his accident was a mere trifle when set beside what had befallen me in that benighted moment, because thanks to the occult tyrannies of those blandly saluting clocks I had been mysteriously handcuffed to history, my destinies indissolubly chained to those of my country. For the next three decades, there was to be no escape. Soothsayers had prophesied me, newspapers celebrated my arrival, politicos ratified my authenticity. I was left entirely without a say in the matter. I, Saleem Sinai, later variously called Snotnose, Stainface, Baldy, Sniffer, Buddha and even Piece-of-the-Moon, had become heavily embroiled in Fate—at the best of times a dangerous sort of involvement. And I couldn’t even wipe my own nose at the time. Now, however, time (having no further use for me) is running out. I will soon be thirty-one years old. Perhaps. If my crumbling, overused body permits. But I have no hope of saving my life, nor can I count on having even a thousand nights and a night. I must work fast, faster than Scheherazade, if I am to end up meaning — yes, meaning — something. I admit it: above all things, I fear absurdity.\n"
     ]
    }
   ],
   "source": [
    "f = open('/Users/blakemyers/texts/english.txt', 'r')\n",
    "file_contents = f.read()\n",
    "print (\"Sample Text: \" + file_contents)\n",
    "f.close()\n",
    "\n",
    "# The original text that we ran with the above program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The summary that we extracted manually:\n",
    "#I was born in Bombay on August 15th, 1947, at midnight,\n",
    "#at the precise instant of India’s independence. I will soon be\n",
    "#thirty-one years old. I must work fast if I am to end up\n",
    "#meaning something. I fear absurdity.\"\n",
    "\n",
    "#The kewords that we extracted manually:\n",
    "#born; midnight, India; independence; meaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
