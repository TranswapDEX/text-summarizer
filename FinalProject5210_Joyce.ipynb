{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import csv\n",
    "import os\n",
    "import networkx as nx\n",
    "import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP :\n",
    "  def __init__(self,lang='en'):\n",
    "    #stanza.download(lang)\n",
    "    self.nlp = stanza.Pipeline(lang=lang,logging_level='WARN')\n",
    "\n",
    "  def from_file(self,fname='texts/english'):\n",
    "    self.fname=fname\n",
    "    text = file2text(fname + \".txt\")\n",
    "    self.doc = self.nlp(text)\n",
    "\n",
    "  def from_text(self,text=\"Hello!\"):\n",
    "    self.doc = self.nlp(text)\n",
    "\n",
    "  def keynoun(self,x):\n",
    "    return  x.upos == 'NOUN' and ('subj' in x.deprel or 'ob' in x.deprel)\n",
    "\n",
    "  def facts(self):\n",
    "    def fact(x,sent,sid) :\n",
    "      if x.head==0 :\n",
    "        yield x.lemma,x.upos+'_PREDICATE_OF',sid,sid\n",
    "      else :\n",
    "        hw=sent.words[x.head-1]\n",
    "        if self.keynoun(x):\n",
    "          yield hw.lemma, hw.upos + \"rev_\"+x.deprel + x.upos, x.lemma, sid\n",
    "          yield (sid, 'ABOUT', x.lemma, sid)\n",
    "        else:\n",
    "          yield x.lemma,x.upos+x.deprel+hw.upos,hw.lemma,sid\n",
    "        if  x.deprel in (\"compound\",\"flat\") :\n",
    "          comp = x.lemma+\" \"+hw.lemma\n",
    "          yield x.lemma, x.upos+\"inCOMPOUND\", comp, sid\n",
    "          yield hw.lemma, hw.upos + \"inCOMPOUND\", comp, sid\n",
    "          yield (sid, 'ABOUT', comp, sid)\n",
    "\n",
    "    for sid,sent in enumerate(self.doc.sentences) :\n",
    "      for x in sent.words :\n",
    "        yield from fact(x,sent,sid)\n",
    "\n",
    "  def keynouns(self):\n",
    "    '''collects important nouns'''\n",
    "    ns=set()\n",
    "    for sent in self.doc.sentences:\n",
    "      for x in sent.words:\n",
    "        if self.keynoun(x) :\n",
    "          ns.add(x.lemma)\n",
    "    return ns\n",
    "\n",
    "  def info(self,wk=8,sk=6):\n",
    "    g=self.to_nx()\n",
    "    ranks=nx.pagerank(g)\n",
    "    ns=self.keynouns()\n",
    "    kwds,sids=ranks2info(ranks,ns,wk,sk)\n",
    "    sents=list(map(self.get_sent,sorted(sids)))\n",
    "    return kwds,sents\n",
    "\n",
    "  def to_nx(self):\n",
    "    return facts2nx(self.facts())\n",
    "\n",
    "  def to_tsv(self):\n",
    "    facts2tsv(self.facts(),\"out/\"+self.fname+\".tsv\")\n",
    "    self.to_sents()\n",
    "\n",
    "  def to_prolog(self):\n",
    "    facts2prolog(self.facts(),\"out/\"+self.fname+\".pro\")\n",
    "\n",
    "  def get_sent(self,sid) :\n",
    "    return self.doc.sentences[sid].text\n",
    "\n",
    "  def to_sents(self):\n",
    "    def sent_gen():\n",
    "       for sid,sent in enumerate(self.doc.sentences):\n",
    "         yield sid,sent.text\n",
    "    facts2tsv(sent_gen(),\"out/\"+self.fname+\"_sents.tsv\")\n",
    "\n",
    "  def summarize(self,wk=8,sk=5):\n",
    "    kws,sents=self.info(wk,sk)\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    for sent in sents : print(sent)\n",
    "    print(\"\\nKEYWORDS:\")\n",
    "    for w in kws : print(w,end='; ')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2text(fname) :\n",
    "  with open(fname,'r') as f:\n",
    "    return f.read()\n",
    "\n",
    "def facts2nx(fgen) :\n",
    "   g=nx.DiGraph()\n",
    "   for f,rel,t,id in fgen :\n",
    "     g.add_edge(f,t)\n",
    "   return g\n",
    "\n",
    "def ranks2info(ranks,keyns,wk,sk) :\n",
    "  ranked=sorted(ranks.items(),key=(lambda x: x[1]),reverse=True)\n",
    "  sids=[]\n",
    "  kwds=[]\n",
    "  for x, r in ranked:\n",
    "    if wk<=0 : break\n",
    "    if isinstance(x,str) and x in keyns:\n",
    "      kwds.append(x)\n",
    "      wk-=1\n",
    "  for x,r in ranked:\n",
    "    if sk <= 0: break\n",
    "    if isinstance(x, int):\n",
    "      sids.append(x)\n",
    "      sk -= 1\n",
    "  return kwds,sids\n",
    "\n",
    "def facts2tsv(fgen,fname) :\n",
    "  ensure_path(fname)\n",
    "  with open(fname, 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    for fact in fgen:\n",
    "      writer.writerow(fact)\n",
    "\n",
    "def facts2prolog(fgen,fname) :\n",
    "  ensure_path(fname)\n",
    "  with open(fname, 'w') as f:\n",
    "    for fact in fgen:\n",
    "      print('edge',end='',file=f)\n",
    "      print(fact,end=\".\\n\",file=f)\n",
    "\n",
    "def exists_file(fname):\n",
    "  return os.path.exists(fname)\n",
    "\n",
    "def home_dir() :\n",
    "  from pathlib import Path\n",
    "  return str(Path.home())\n",
    "\n",
    "def ensure_path(fname) :\n",
    "  dir,_=os.path.split(fname)\n",
    "  os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY:\n",
      "for an instant towards\n",
      "A\n",
      "speck of dust on the patent leather of her boot.\n",
      "Wet bright bills for next week.\n",
      "Funny sight two of them together, their bellies out.\n",
      "Spaton sawdust, sweetish warmish cigarette smoke, reek of\n",
      "plug, spilt beer, men's beery piss, the stale of ferment.\n",
      "\n",
      "KEYWORDS:\n",
      "eye; man; time; face; hand; day; voice; one; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(fname='texts/english',lang='en') :\n",
    "  nlp=NLP(lang)\n",
    "  nlp.from_file(fname)\n",
    "  nlp.to_tsv()\n",
    "  nlp.to_prolog()\n",
    "  nlp.summarize()\n",
    "\n",
    "if __name__==\"__main__\" :\n",
    "  test(fname='texts/english',lang='en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
